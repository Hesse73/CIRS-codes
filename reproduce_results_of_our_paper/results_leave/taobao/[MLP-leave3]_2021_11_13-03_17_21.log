[I 211113 03:17:21 MLP-taobao:91] {
      "resume": false,
      "env": "VirtualTB-v0",
      "feature_dim": 4,
      "model_name": "MLP-RL",
      "dnn": [
        256,
        256
      ],
      "batch_size": 100,
      "epoch": 10,
      "cuda": 2,
      "leave_threshold": 3.0,
      "num_leave_compute": 5,
      "message": "MLP-leave3"
    }
[I 211113 03:18:12 utils:39] Epoch: [0], Info: [{'loss': 0.5302573042297364, 'RL_val_CTR': 3.77, 'RL_val_click_loss': 2.5215261157840723, 'RL_val_trajectory_len': 2.0, 'RL_val_trajectory_reward': 7.54}]
[I 211113 03:18:44 utils:39] Epoch: [1], Info: [{'loss': 0.11371365866184234, 'RL_val_CTR': 3.99, 'RL_val_click_loss': 2.2694125548843296, 'RL_val_trajectory_len': 2.0, 'RL_val_trajectory_reward': 7.98}]
[I 211113 03:19:09 utils:39] Epoch: [2], Info: [{'loss': 0.023566209364533425, 'RL_val_CTR': 4.45, 'RL_val_click_loss': 2.4303224455099555, 'RL_val_trajectory_len': 2.0, 'RL_val_trajectory_reward': 8.9}]
[I 211113 03:19:42 utils:39] Epoch: [3], Info: [{'loss': 0.0059142127481102945, 'RL_val_CTR': 3.86, 'RL_val_click_loss': 2.2255029752105475, 'RL_val_trajectory_len': 2.0, 'RL_val_trajectory_reward': 7.72}]
[I 211113 03:20:16 utils:39] Epoch: [4], Info: [{'loss': 0.002983564877361059, 'RL_val_CTR': 4.18, 'RL_val_click_loss': 2.174022106816992, 'RL_val_trajectory_len': 2.0, 'RL_val_trajectory_reward': 8.36}]
[I 211113 03:20:49 utils:39] Epoch: [5], Info: [{'loss': 0.002578653610292822, 'RL_val_CTR': 4.32, 'RL_val_click_loss': 2.237204128399026, 'RL_val_trajectory_len': 2.0, 'RL_val_trajectory_reward': 8.64}]
[I 211113 03:21:22 utils:39] Epoch: [6], Info: [{'loss': 0.0025416978589072824, 'RL_val_CTR': 4.155, 'RL_val_click_loss': 2.156874608057551, 'RL_val_trajectory_len': 2.0, 'RL_val_trajectory_reward': 8.31}]
[I 211113 03:21:50 utils:39] Epoch: [7], Info: [{'loss': 0.0025403404553048315, 'RL_val_CTR': 4.45, 'RL_val_click_loss': 2.2790273577999325, 'RL_val_trajectory_len': 2.0, 'RL_val_trajectory_reward': 8.9}]
[I 211113 03:22:12 utils:39] Epoch: [8], Info: [{'loss': 0.002539649624712765, 'RL_val_CTR': 4.3, 'RL_val_click_loss': 2.228059718720615, 'RL_val_trajectory_len': 2.0, 'RL_val_trajectory_reward': 8.6}]
[I 211113 03:22:32 utils:39] Epoch: [9], Info: [{'loss': 0.002541052774898708, 'RL_val_CTR': 4.07, 'RL_val_click_loss': 2.1386994696874173, 'RL_val_trajectory_len': 2.0, 'RL_val_trajectory_reward': 8.14}]
[I 211113 03:22:32 MLP-taobao:139] {'loss': [0.5302573042297364, 0.11371365866184234, 0.023566209364533425, 0.0059142127481102945, 0.002983564877361059, 0.002578653610292822, 0.0025416978589072824, 0.0025403404553048315, 0.002539649624712765, 0.002541052774898708], 'RL_val_CTR': [3.77, 3.99, 4.45, 3.86, 4.18, 4.32, 4.155, 4.45, 4.3, 4.07], 'RL_val_click_loss': [2.5215261157840723, 2.2694125548843296, 2.4303224455099555, 2.2255029752105475, 2.174022106816992, 2.237204128399026, 2.156874608057551, 2.2790273577999325, 2.228059718720615, 2.1386994696874173], 'RL_val_trajectory_len': [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], 'RL_val_trajectory_reward': [7.54, 7.98, 8.9, 7.72, 8.36, 8.64, 8.31, 8.9, 8.6, 8.14]}
